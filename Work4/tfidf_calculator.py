import os
import math
from collections import defaultdict
from tqdm import tqdm

def load_lemmas(lemmas_file):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ª–µ–º–º –∏–∑ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    lemmas_dict = {}
    try:
        with open(lemmas_file, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if not parts:
                    continue
                lemma = parts[0]
                tokens = parts[1:] if len(parts) > 1 else []
                lemmas_dict[lemma] = tokens
    except Exception as e:
        tqdm.write(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {lemmas_file}: {str(e)}")
    return lemmas_dict

def calculate_tf(tokens):
    """–†–∞—Å—á—ë—Ç TF —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    tf = defaultdict(float)
    total = len(tokens)
    if total == 0:
        return tf
    for token in tokens:
        tf[token] += 1
    return {k: v / total for k, v in tf.items()}

def calculate_idf(docs_items):
    """–†–∞—Å—á—ë—Ç IDF —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    idf = defaultdict(float)
    total_docs = len(docs_items)
    if total_docs == 0:
        return idf

    doc_freq = defaultdict(int)
    for doc in tqdm(docs_items, desc="üìä IDF", unit="–¥–æ–∫"):
        unique_items = set(doc)
        for item in unique_items:
            doc_freq[item] += 1

    return {
        item: max(0.0, math.log((total_docs + 1) / (count + 1)) + 1)
        for item, count in doc_freq.items()
    }

def process_tfidf():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º"""
    input_dir = "../Work2/result"
    output_dir = "result"
    os.makedirs(f"{output_dir}/terms", exist_ok=True)
    os.makedirs(f"{output_dir}/lemmas", exist_ok=True)

    # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    files = [
        f.split("-lemmas.txt")[0]
        for f in os.listdir(input_dir)
        if f.endswith("-lemmas.txt")
    ]

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    all_data = []
    for name in tqdm(files, desc="üìÇ –ó–∞–≥—Ä—É–∑–∫–∞"):
        lemma_file = os.path.join(input_dir, f"{name}-lemmas.txt")
        token_file = os.path.join(input_dir, f"{name}-tokens.txt")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        if not os.path.exists(lemma_file):
            tqdm.write(f"üö® –§–∞–π–ª {lemma_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue
        if not os.path.exists(token_file):
            tqdm.write(f"üö® –§–∞–π–ª {token_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue

        lemmas = load_lemmas(lemma_file)
        try:
            with open(token_file, 'r', encoding='utf-8') as f:
                tokens = [line.strip() for line in f if line.strip()]
        except Exception as e:
            tqdm.write(f"üö® –û—à–∏–±–∫–∞ {token_file}: {e}")
            continue

        all_data.append((name, lemmas, tokens))

    # –†–∞—Å—á—ë—Ç IDF –¥–ª—è —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –ª–µ–º–º
    idf_terms = calculate_idf([d[2] for d in all_data])
    idf_lemmas = calculate_idf([list(d[1].keys()) for d in all_data])

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    for name, lemmas, tokens in tqdm(all_data, desc="üîß –û–±—Ä–∞–±–æ—Ç–∫–∞"):
        # TF –¥–ª—è —Ç–µ—Ä–º–∏–Ω–æ–≤
        tf_terms = calculate_tf(tokens)

        # –ó–∞–ø–∏—Å—å —Ç–µ—Ä–º–∏–Ω–æ–≤
        try:
            with open(f"{output_dir}/terms/{name}_terms.txt", "w", encoding="utf-8") as f:
                for term, tf in tf_terms.items():
                    idf_val = idf_terms.get(term, 0.0)
                    tfidf_val = tf * idf_val
                    f.write(f"{term} {idf_val:.4f} {tfidf_val:.4f}\n")
        except Exception as e:
            tqdm.write(f"üö® –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ terms {name}: {e}")

        # TF –∏ TF-IDF –¥–ª—è –ª–µ–º–º
        total_terms = len(tokens)
        if total_terms == 0:
            continue

        lemma_scores = {}
        for lemma, words in lemmas.items():
            # TF –ª–µ–º–º—ã: —Å—É–º–º–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤ / –æ–±—â–µ–µ —á–∏—Å–ª–æ —Ç–µ—Ä–º–∏–Ω–æ–≤
            count = sum(1 for token in tokens if token in words)
            tf_lemma = count / total_terms
            # TF-IDF –ª–µ–º–º—ã
            lemma_scores[lemma] = tf_lemma * idf_lemmas.get(lemma, 0.0)

        # –ó–∞–ø–∏—Å—å –ª–µ–º–º
        try:
            with open(f"{output_dir}/lemmas/{name}_lemmas.txt", "w", encoding="utf-8") as f:
                for lemma, score in lemma_scores.items():
                    idf_val = idf_lemmas.get(lemma, 0.0)
                    f.write(f"{lemma} {idf_val:.4f} {score:.4f}\n")
        except Exception as e:
            tqdm.write(f"üö® –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ lemmas {name}: {e}")

if __name__ == "__main__":
    process_tfidf()